{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:42:21.160593700Z",
     "start_time": "2023-12-23T14:42:14.268030600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sktime.clustering.k_means import TimeSeriesKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sktime.datatypes import convert_to\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import pearsonr\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:49:51.924541300Z",
     "start_time": "2023-12-23T14:49:51.913115400Z"
    }
   },
   "id": "6d70a9964df969fd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fct_df  = pd.read_csv(\"yfinance_data.csv\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:42:22.341474100Z",
     "start_time": "2023-12-23T14:42:21.615914900Z"
    }
   },
   "id": "d07068fe0f206d28"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serga\\AppData\\Local\\Temp\\ipykernel_24020\\3888624228.py:3: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise a warning unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  fct_df['date'] = pd.to_datetime(fct_df['date'])\n",
      "C:\\Users\\serga\\AppData\\Local\\Temp\\ipykernel_24020\\3888624228.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fct_df['date'] = pd.to_datetime(fct_df['date'])\n"
     ]
    }
   ],
   "source": [
    "fct_df.columns = fct_df.columns.str.lower()\n",
    "fct_df  = fct_df[['date','open','close','ticker']]\n",
    "fct_df['date'] = pd.to_datetime(fct_df['date'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:45:30.551886Z",
     "start_time": "2023-12-23T14:45:27.333145100Z"
    }
   },
   "id": "497c0e462f809dac"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2018-12-04 00:00:00-05:00 - 2021-12-03 00:00:00-05:00\n",
      "Validation period: 2021-12-06 00:00:00-05:00 - 2022-12-02 00:00:00-05:00\n",
      "Test period: 2022-12-05 00:00:00-05:00 - 2023-12-04 00:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "min_date = fct_df['date'].min()\n",
    "max_date = fct_df['date'].max()\n",
    "\n",
    "train_end = min_date + pd.DateOffset(years=3) \n",
    "valid_end = train_end + pd.DateOffset(years=1) \n",
    "test_end = max_date\n",
    "\n",
    "train_df = fct_df[fct_df['date'] <= train_end] #на данном датасете считаются статистики и подбираются оптимальные пары\n",
    "valid_df = fct_df[(fct_df['date'] > train_end) & (fct_df['date'] <= valid_end)] #на данном датасете оптимизируется торговая стратегия\n",
    "test_df = fct_df[fct_df['date'] > valid_end] #на данном датасете применяется стратегия и делается заключение о применимости метода\n",
    "\n",
    "print(f'Train period: {min(train_df[\"date\"])} - {max(train_df[\"date\"])}')\n",
    "print(f'Validation period: {min(valid_df[\"date\"])} - {max(valid_df[\"date\"])}')\n",
    "print(f'Test period: {min(test_df[\"date\"])} - {max(test_df[\"date\"])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:45:33.026901800Z",
     "start_time": "2023-12-23T14:45:32.294222500Z"
    }
   },
   "id": "beeed3d0ff7250fa"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "data = train_df['close'].values\n",
    "\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps)])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 5  \n",
    "X, y = create_sequences(data, time_steps)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Предполагая, что X_train и y_train - это ваши обучающие данные, преобразованные в PyTorch Tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "\n",
    "# Создание TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_data = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:49:58.421552900Z",
     "start_time": "2023-12-23T14:49:57.910397100Z"
    }
   },
   "id": "6abb97a4653ff858"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "model = LSTMModel(input_size=5, hidden_layer_size=100, output_size=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:52:32.283982300Z",
     "start_time": "2023-12-23T14:52:32.270714500Z"
    }
   },
   "id": "ca15dcc2726f93d0"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1, got 5",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 11\u001B[0m\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mhidden_cell \u001B[38;5;241m=\u001B[39m (torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, model\u001B[38;5;241m.\u001B[39mhidden_layer_size),\n\u001B[0;32m      9\u001B[0m                      torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, model\u001B[38;5;241m.\u001B[39mhidden_layer_size))\n\u001B[1;32m---> 11\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model(seq)\n\u001B[0;32m     13\u001B[0m single_loss \u001B[38;5;241m=\u001B[39m loss_function(y_pred, labels)\n\u001B[0;32m     14\u001B[0m single_loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[15], line 14\u001B[0m, in \u001B[0;36mLSTMModel.forward\u001B[1;34m(self, input_seq)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_seq):\n\u001B[1;32m---> 14\u001B[0m     lstm_out, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_cell \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm(input_seq\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;28mlen\u001B[39m(input_seq), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_cell)\n\u001B[0;32m     15\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(lstm_out\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;28mlen\u001B[39m(input_seq), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:875\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    872\u001B[0m             hx \u001B[38;5;241m=\u001B[39m (hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    873\u001B[0m         \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[0;32m    874\u001B[0m         \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n\u001B[1;32m--> 875\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    876\u001B[0m         hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[0;32m    878\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:790\u001B[0m, in \u001B[0;36mLSTM.check_forward_args\u001B[1;34m(self, input, hidden, batch_sizes)\u001B[0m\n\u001B[0;32m    785\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_forward_args\u001B[39m(\u001B[38;5;28mself\u001B[39m,  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[0;32m    786\u001B[0m                        \u001B[38;5;28minput\u001B[39m: Tensor,\n\u001B[0;32m    787\u001B[0m                        hidden: Tuple[Tensor, Tensor],\n\u001B[0;32m    788\u001B[0m                        batch_sizes: Optional[Tensor],\n\u001B[0;32m    789\u001B[0m                        ):\n\u001B[1;32m--> 790\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_input(\u001B[38;5;28minput\u001B[39m, batch_sizes)\n\u001B[0;32m    791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_hidden_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[0;32m    792\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[0] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_cell_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[0;32m    794\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[1] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PairTradingProject\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:236\u001B[0m, in \u001B[0;36mRNNBase.check_input\u001B[1;34m(self, input, batch_sizes)\u001B[0m\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput must have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_input_dim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m dimensions, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.size(-1) must be equal to input_size. Expected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: input.size(-1) must be equal to input_size. Expected 1, got 5"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 150\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_data:  # train_data - это ваш DataLoader\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                             torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:50:10.234021500Z",
     "start_time": "2023-12-23T14:50:09.430575900Z"
    }
   },
   "id": "ea5b1aea44c04252"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7528518b8156a918"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
